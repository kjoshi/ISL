{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exercises\n",
    "## Conceptual\n",
    "\n",
    "### 1.\n",
    "Describe the null hypotheses to which the p-values given in Table 3.4\n",
    "correspond. Explain what conclusions you can draw based on these\n",
    "p-values. Your explanation should be phrased in terms of sales, TV,\n",
    "radio, and newspaper, rather than in terms of the coefficients of the\n",
    "linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Answer:\n",
    "The null hypothesis is that that variables `TV`, `radio` and `newspaper` do *not* have an effect on sales I.e.\n",
    "\n",
    "$H_0^{(1)} : \\beta_1 = 0 \\qquad H_0^{(2)}: \\beta_2 = 0 \\qquad H_0^{(3)}: \\beta_3 = 0 $\n",
    "\n",
    "The p-values associated with $\\beta_1, \\beta_2$  and $\\beta_3$ are $<0.0001, <0.0001$ and $0.8599$.\n",
    "\n",
    "The p-value tells us how likely it is to observe an association between the predictor and the response given random chance, in the absence of any reali association (I.e. under the null hypothesis).\n",
    "\n",
    "The p-values for $\\beta_1 $ and $\\beta_2 $ are very small, meaning that we can reject the null hypothesis and say that there *is* a statistically significant relationship between `TV` and `Sales` and `radio` and `Sales`.\n",
    "\n",
    "The p-value for $\\beta_3 $ is close to 1, implying that there is no significant relationship between `newspaper` and `Sales`.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.\n",
    "Carefully explain the differences between the KNN classifier and KNN\n",
    "regression methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Answer:\n",
    "The KNN classifier is used to predict the conditional probability $P(Y=j\\,|\\,X=x_0)$ for class $j$ by calculating the fraction of points in the neighbourhood of $x_0$ which have class $j$.\n",
    "\n",
    "KNN regression is used to predict a value for $f(x_0)$. A neighbour around $x_0$ is identified and the average of all responses in the neighbourhood is taken as $f(x_0)$.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.\n",
    "Suppose we have a data set with five predictors, $X_1$ = GPA, $X_2$ = IQ,\n",
    "$X_3$ = Gender (1 for Female and 0 for Male), $X_4$ = Interaction between\n",
    "GPA and IQ, and $X_5$ = Interaction between GPA and Gender. The\n",
    "response is starting salary after graduation (in thousands of dollars).\n",
    "Suppose we use least squares to fit the model, and get $\\hat\\beta_0 = 50$, $\\hat\\beta_1 = 20$, $\\hat\\beta_2 = 0.07$, $\\hat\\beta_3 = 35$, $\\hat\\beta_4 = 0.01$, $\\hat\\beta_5 = −10$.\n",
    "\n",
    "1. Which answer is correct, and why?\n",
    "  1. For a fixed value of IQ and GPA, males earn more on average than females.\n",
    "  2. For a fixed value of IQ and GPA, females earn more on average than males.\n",
    "  3. For a fixed value of IQ and GPA, males earn more on average than females provided that the GPA is high enough.\n",
    "  4. For a fixed value of IQ and GPA, females earn more on average than males provided that the GPA is high enough.\n",
    "2. Predict the salary of a female with IQ of 110 and a GPA of 4.0.\n",
    "3. True or false: Since the coefficient for the GPA/IQ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Answer\n",
    "The model is:\n",
    "\n",
    "Salary = $50$ + $20$ x GPA + $0.07$ x IQ + $35$ x Female + $0.01$ x (GPA x IQ) - $10$ x (GPA x Female)\n",
    "\n",
    "1. C is correct.  \n",
    "If GPA is high enough, the negative coefficient in front of GPA x Female cancels out the positive coefficient in front of Female, and results in Males earning more.\n",
    "\n",
    "2. IQ = 110, GPA = 4.0  \n",
    "Salary = 50 + 20x4.0 + 0.07x110 + 35 + 0.01 x 4.0 x 110 - 40  \n",
    "Salary = $137,100\n",
    "\n",
    "3. False  \n",
    "Just because the coefficient is small it doesn't mean that the significance is smaller. Without knowing the standard error we can't state how significant the interaction effect is.  \n",
    "However, it does seem unlikely that such a small coefficient would lead to a significant effect, given the size of the other coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50 + (20*4.0) + (0.07*110) + 35 + (0.01*4.0*110) - 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\n",
    "I collect a set of data (n = 100 observations) containing a single\n",
    "predictor and a quantitative response. I then fit a linear regression\n",
    "model to the data, as well as a separate cubic regression,  \n",
    "i.e. Y = $\\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon$\n",
    "\n",
    "1. Suppose that the true relationship between X and Y is linear,\n",
    "i.e. $Y = \\beta_0 + \\beta_1 X + \\epsilon$ . Consider the training residual sum of\n",
    "squares (RSS) for the linear regression, and also the training\n",
    "RSS for the cubic regression. Would we expect one to be lower\n",
    "than the other, would we expect them to be the same, or is there\n",
    "not enough information to tell? Justify your answer.\n",
    "2. Answer 1. using test rather than training RSS.\n",
    "3. Suppose that the true relationship between X and Y is not linear,\n",
    "but we don’t know how far it is from linear. Consider the training\n",
    "RSS for the linear regression, and also the training RSS for the\n",
    "cubic regression. Would we expect one to be lower than the\n",
    "other, would we expect them to be the same, or is there not\n",
    "enough information to tell? Justify your answer.\n",
    "4. Answer 3. using test rather than training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "1. The training RSS would be lower using the cubic model. The irreducible error in the training sample would lead to the cubic model be able to better describe the variance in the data than the linear model.\n",
    "2. The test RSS would be lower with the linear model. Since the true relationship is linear the cubic model would overfit the training data and lead to large RSS in the test data.\n",
    "3. We would still expect the training RSS to be lower for the cubic model. Adding higher order terms to moel allows it to better fit the training data, whether the non-linearity is caused by variance in the training data or non-linearity in the true relationship.\n",
    "4. There is not enough information to tell. If the true relationship is cubic, then the cubic model will more accurately fit the test data than a linear model. But if no, then both models may fit the test data equally badly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n",
    "Consider the fitted values that result from performing linear regression\n",
    "without an intercept. In this setting, the $i$th fitted value takes\n",
    "the form  \n",
    "$$\\hat{y}_i = x_i\\hat\\beta$$\n",
    "where\n",
    "$$ \\beta = \\left(\\sum_{i=1}^n x_iy_i\\right) / \\left(\\sum_{i'=1}^n x_{i'}^2\\right)$$\n",
    "Show that we can write:\n",
    "$$ \\hat{y}_i = \\sum_{i=1}^n a_{i'}y_{i'} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "$$\\hat{y}_i = x_i\\beta = x_i\\frac{\\sum_j x_j y_j}{\\sum_k x_k^2}  = \\sum_j \\frac{x_i x_j}{\\sum_k x_k^2}y_j = \\sum_j a_j y_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\n",
    "Using (3.4), argue that in the case of simple linear regression, the\n",
    "least squares line always passes through the point ($\\bar{x}, \\bar{y}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "The linear regression equation is\n",
    "$$ \\hat{y} = \\beta_0 + \\beta_1 x $$\n",
    "Where $\\beta_0 = \\bar{y} - \\beta_1 \\bar{x}$\n",
    "\n",
    "Therefore\n",
    "$$ \\hat{y} = \\bar{y} - \\beta_1 \\bar{x} + \\beta_1 x $$\n",
    "\n",
    "So if $x = \\bar{x}$, \n",
    "$$ \\hat{y} = \\bar{y} - \\beta_1 \\bar{x} + \\beta_1 \\bar{x} = \\bar{y} $$\n",
    "\n",
    "Therefore we conclude that the line passes through the point $(\\bar{x}, \\bar{y})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\n",
    "It is claimed in the text that in the case of simple linear regression\n",
    "of Y onto X, the R2 statistic (3.17) is equal to the square of the\n",
    "correlation between X and Y (3.18). Prove that this is the case. For\n",
    "simplicity, you may assume that $\\bar{x} = \\bar{y} = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "$$ R^2 = 1 - \\frac{RSS}{TSS} = 1 - \\frac{\\sum_i(y_i - \\hat{y}_i)^2}{\\sum_i(y_i - \\bar{y})^2}$$\n",
    "Using $\\bar{x} = \\bar{y} = 0$, we have:\n",
    "$$ R^2 = 1 - \\frac{\\sum_i(y_i - \\hat{y}_i)^2}{\\sum_i(y_i)^2} $$\n",
    "and\n",
    "$$ \\hat{y}_i = \\beta_0 + \\beta_1 x_i = \\bar{y} - \\beta_1 \\bar{x} + \\beta_1 x_i = \\beta_1 x_i = x_i\\frac{\\sum_j x_j y_j}{\\sum_k x_k^2} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substituting into $R^2$ and expanding:\n",
    "\n",
    "$$ R^2 = 1 - \\frac{\\sum_i(y_i - [x_i\\sum_j x_j y_j / \\sum_k x_k^2])^2}{\\sum_i y_i^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ R^2 = \\frac{\\sum_i y_i^2 - (\\sum_i y_i^2 - 2 \\sum_i y_i x_i \\sum_j x_j y_j / \\sum_k x_k^2 + \\sum_i x_i^2 (\\sum_j x_j y_j)^2 / \\sum_k x_k^4}{\\sum_i y_i^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ R^2 = \\frac{2 (\\sum_i x_i y_i)^2 / \\sum_k x_k^2 - (\\sum_j x_j y_j)^2 / \\sum_k x_k^2}{\\sum_i y_i^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ R^2 = \\frac{(\\sum_i x_i y_i)^2}{\\sum_i x_i^2 \\sum_i y_i^2}  \\equiv Corr(X,Y)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
